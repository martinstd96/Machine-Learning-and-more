{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ryPRvoIRtf0g"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OcWtjmTvz1B5","outputId":"b32e4be5-f110-4039-92c8-a8f25d8ef916"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: category_encoders in /home/martin/.local/lib/python3.8/site-packages (2.3.0)\n","Requirement already satisfied: numpy>=1.14.0 in /home/martin/.local/lib/python3.8/site-packages (from category_encoders) (1.22.0)\n","Requirement already satisfied: statsmodels>=0.9.0 in /home/martin/.local/lib/python3.8/site-packages (from category_encoders) (0.13.1)\n","Requirement already satisfied: patsy>=0.5.1 in /home/martin/.local/lib/python3.8/site-packages (from category_encoders) (0.5.2)\n","Requirement already satisfied: scipy>=1.0.0 in /home/martin/.local/lib/python3.8/site-packages (from category_encoders) (1.7.3)\n","Requirement already satisfied: pandas>=0.21.1 in /home/martin/.local/lib/python3.8/site-packages (from category_encoders) (1.3.5)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /home/martin/.local/lib/python3.8/site-packages (from category_encoders) (1.0.2)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.1->category_encoders) (1.14.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas>=0.21.1->category_encoders) (2019.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas>=0.21.1->category_encoders) (2.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/martin/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /home/martin/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n"]}],"source":["!pip install category_encoders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIRDUH3wz20w"},"outputs":[],"source":["import sys\n","sys.path.insert(0,'/drive/My Drive/TP_Datos_2C2021/parte_2/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtdboQYOz3dq"},"outputs":[],"source":["from preprocessing import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpix0Mvpz5Gw","outputId":"45a32d5f-15df-4603-a111-011f8b53a181"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xgboost in /home/martin/.local/lib/python3.8/site-packages (1.5.1)\r\n","Requirement already satisfied: numpy in /home/martin/.local/lib/python3.8/site-packages (from xgboost) (1.22.0)\r\n","Requirement already satisfied: scipy in /home/martin/.local/lib/python3.8/site-packages (from xgboost) (1.7.3)\r\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# haciendo los graficos un poco mas bonitos en matplotlib\n","plt.style.use('default') \n","#plt.rcParams['figure.figsize'] = (20, 10)\n","\n","plt.rcParams['figure.dpi'] = 70\n","\n","# seteando tipo de grid en seaborn\n","sns.set_theme(style='ticks', palette=None, font_scale=.9) \n","\n","#filtrado de warnings\n","warnings.filterwarnings('ignore')\n","\n","!pip install xgboost\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVTBW9Ep0eaw"},"outputs":[],"source":["hamburguesas_values, hamburguesas_target, hamburguesas_test = descargar_datasets(\n","    url_values = 'https://docs.google.com/spreadsheets/d/1wduqo5WyYmCpaGnE81sLNGU0VSodIekMfpmEwU0fGqs',\n","    url_target = 'https://docs.google.com/spreadsheets/d/1gvZ03uAL6THwd04Y98GtIj6SeAHiKyQY5UisuuyFSUs', \n","    url_test = 'https://docs.google.com/spreadsheets/d/1mR_JNN0-ceiB5qV42Ff9hznz0HtWaoPF3B9zNGoNPY8'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsN34xQ80i9Z"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    hamburguesas_values, \n","    hamburguesas_target, \n","    test_size=0.4,\n","    random_state=66, \n","    stratify=hamburguesas_target.llovieron_hamburguesas_al_dia_siguiente.astype(str)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6SjvAOrcg4oZ"},"outputs":[],"source":["X_val_dev, X_test_holdout, y_val_dev, y_test_holdout = train_test_split(\n","    X_test, \n","    y_test, \n","    test_size=0.1,\n","    random_state=66, \n","    stratify=y_test.llovieron_hamburguesas_al_dia_siguiente.astype(str)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jo7fsOKo1SDo"},"outputs":[],"source":["#hamburguesas_values_sn, hamburguesas_val_dev_sn, hamburguesas_hold_out_sn = knn_imputer(X_train, X_val_dev, X_holdout)\n","#hamburguesas_val_dev_sn = knn_imputer(X_val_dev)\n","#hamburguesas_test_sn = knn_imputer(hamburguesas_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6N82af4sX5c"},"outputs":[],"source":["#hamburguesas_values_escalado = standar_scaler(hamburguesas_values_sn)\n","#hamburguesas_val_dev_escalado = standar_scaler(hamburguesas_val_dev_sn)\n","#hamburguesas_test_escalado = standar_scaler(hamburguesas_test_sn)"]},{"cell_type":"markdown","metadata":{"id":"Q-tZuPf7Vs-I"},"source":["# Knn imputer, robust scaler, one hot encoding y hashing trick"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjtW7XhDVgal"},"outputs":[],"source":["hamburguesas_train_values_ht, hamburguesas_val_dev_values_ht, X_test_holdout_sn = preprocessing_knn_imputer_robust_escaler_one_hot_encoding_hashing_trick(\n","    X_train, \n","    X_val_dev, \n","    X_test_holdout\n",")\n","\n","#hamburguesas_train_values_ht = hashing_trick_ecoding(hamburguesas_values_escalado)\n","hamburguesas_train_target_enc = y_train['llovieron_hamburguesas_al_dia_siguiente'].map({'no': 0, 'si': 1, np.NaN: 0})\n","#hamburguesas_val_dev_values_ht = hashing_trick_ecoding(hamburguesas_val_dev_escalado)\n","hamburguesas_val_dev_target_enc = y_val_dev['llovieron_hamburguesas_al_dia_siguiente'].map({'no': 0, 'si': 1, np.NaN: 0})"]},{"cell_type":"markdown","metadata":{"id":"CQ9CCdecz6lO"},"source":["## Selección de features"]},{"cell_type":"markdown","metadata":{"id":"0EQKAAo26CS_"},"source":["* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n","* https://scikit-learn.org/stable/modules/ensemble.html\n","* https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n","* https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6646,"status":"ok","timestamp":1639017279296,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"7Tqm0EIWVr5v","outputId":"eb61bfc9-7ef1-40ab-8008-d5943d2bf08f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[12:12:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n","              gamma=0, gpu_id=-1, importance_type=None,\n","              interaction_constraints='', learning_rate=0.300000012,\n","              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n","              monotone_constraints='()', n_estimators=100, n_jobs=8,\n","              num_parallel_tree=1, predictor='auto', random_state=0,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n","              tree_method='exact', validate_parameters=1, verbosity=None)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["modelo = XGBClassifier()\n","modelo.fit(hamburguesas_train_values_ht, hamburguesas_train_target_enc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUOoz9Tvva7J"},"outputs":[],"source":["importancia = []\n","for i in range (len(modelo.feature_importances_)):\n","  importancia.append((modelo.feature_importances_[i], hamburguesas_train_values_ht.columns[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1639017282784,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"mEacwmAYvp3w","outputId":"d0b37fc1-4280-4752-e87b-dd6f2a3fcc0e"},"outputs":[{"data":{"text/plain":["[(0.17083405, 'humedad_tarde'),\n"," (0.04413148, 'rafaga_viento_max_velocidad'),\n"," (0.039118126, 'nubosidad_tarde'),\n"," (0.03154117, 'mm_lluvia_dia'),\n"," (0.023683134, 'presion_atmosferica_tarde'),\n"," (0.02183488, 'horas_de_sol'),\n"," (0.016706496, 'mes'),\n"," (0.016226994, 'presion_atmosferica_temprano'),\n"," (0.015455248, 'direccion_viento_temprano_Sursureste'),\n"," (0.014866387, 'direccion_viento_tarde_Oeste'),\n"," (0.01435606, 'temperatura_temprano'),\n"," (0.0143351145, 'humedad_temprano'),\n"," (0.014222059, 'velocidad_viendo_tarde'),\n"," (0.0133938445, 'rafaga_viento_max_direccion_Este'),\n"," (0.013358506, 'rafaga_viento_max_direccion_Noreste'),\n"," (0.013235049, 'rafaga_viento_max_direccion_Noroeste'),\n"," (0.013003576, 'rafaga_viento_max_direccion_Suroeste'),\n"," (0.012690766, 'temp_max'),\n"," (0.012689785, 'temperatura_tarde'),\n"," (0.012640199, 'temp_min'),\n"," (0.012622951, 'direccion_viento_temprano_Sureste'),\n"," (0.012353858, 'velocidad_viendo_temprano'),\n"," (0.012275311, 'direccion_viento_tarde_Estenoreste'),\n"," (0.011894239, 'mm_evaporados_agua'),\n"," (0.011498996, 'direccion_viento_temprano_Sur'),\n"," (0.011412751, 'nubosidad_temprano'),\n"," (0.011351352, 'direccion_viento_tarde_Estesureste'),\n"," (0.011134981, 'rafaga_viento_max_direccion_Norte'),\n"," (0.0110949315, 'col_4'),\n"," (0.011001318, 'llovieron_hamburguesas_hoy_Si'),\n"," (0.010984594, 'direccion_viento_tarde_Noroeste'),\n"," (0.010812643, 'rafaga_viento_max_direccion_Estesureste'),\n"," (0.010641587, 'direccion_viento_temprano_Noroeste'),\n"," (0.010547626, 'rafaga_viento_max_direccion_Oestesuroeste'),\n"," (0.010460314, 'direccion_viento_temprano_Oestesuroeste'),\n"," (0.010366668, 'col_3'),\n"," (0.010230688, 'anio'),\n"," (0.010227132, 'rafaga_viento_max_direccion_Sursureste'),\n"," (0.010171719, 'direccion_viento_temprano_Noreste'),\n"," (0.010097077, 'rafaga_viento_max_direccion_Sureste'),\n"," (0.010054204, 'direccion_viento_tarde_Sur'),\n"," (0.009995883, 'direccion_viento_temprano_Oeste'),\n"," (0.009960521, 'direccion_viento_temprano_Oestenoroeste'),\n"," (0.009935608, 'rafaga_viento_max_direccion_Oestenoroeste'),\n"," (0.009889674, 'direccion_viento_temprano_Nornoreste'),\n"," (0.009841254, 'direccion_viento_tarde_Suroeste'),\n"," (0.009771014, 'direccion_viento_temprano_Suroeste'),\n"," (0.009649208, 'direccion_viento_tarde_Sursuroeste'),\n"," (0.009588891, 'dia'),\n"," (0.00929952, 'direccion_viento_tarde_Norte'),\n"," (0.009247764, 'rafaga_viento_max_direccion_Nornoreste'),\n"," (0.008996479, 'direccion_viento_tarde_Oestesuroeste'),\n"," (0.008902536, 'direccion_viento_temprano_Estenoreste'),\n"," (0.008893559, 'direccion_viento_temprano_Norte'),\n"," (0.00885186, 'direccion_viento_tarde_Noreste'),\n"," (0.008708817, 'rafaga_viento_max_direccion_Sur'),\n"," (0.008662177, 'rafaga_viento_max_direccion_Estenoreste'),\n"," (0.008523748, 'direccion_viento_tarde_Sureste'),\n"," (0.00845822, 'direccion_viento_tarde_Este'),\n"," (0.008371562, 'col_0'),\n"," (0.008268176, 'llovieron_hamburguesas_hoy_No'),\n"," (0.008243178, 'col_2'),\n"," (0.008232611, 'col_1'),\n"," (0.0075046862, 'direccion_viento_tarde_Oestenoroeste'),\n"," (0.00738677, 'rafaga_viento_max_direccion_Oeste'),\n"," (0.007286692, 'direccion_viento_tarde_Nornoreste'),\n"," (0.0070409686, 'direccion_viento_tarde_Sursureste'),\n"," (0.0061645643, 'direccion_viento_temprano_Este'),\n"," (0.0047661136, 'direccion_viento_temprano_Estesureste'),\n"," (0.0, 'rafaga_viento_max_direccion_Sursuroeste'),\n"," (0.0, 'direccion_viento_temprano_Sursuroeste')]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["importancia.sort(reverse=True)\n","importancia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3IexsYlYvuAw"},"outputs":[],"source":["aux = importancia[:9] #puede variar\n","columnas_a_usar = []\n","for tupla in aux:\n","  columnas_a_usar.append(tupla[1])"]},{"cell_type":"markdown","metadata":{"id":"wIirqOaK6Mlk"},"source":["Esto es para KNN ya que ese modelo no es lo suficientemente inteligente para saber a qué columnas le debe dar más imporatancia"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1639017287077,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"eErlkwxe49w-","outputId":"f21664aa-3ebe-4471-ded9-1a2051757d92"},"outputs":[{"data":{"text/plain":["['humedad_tarde',\n"," 'rafaga_viento_max_velocidad',\n"," 'nubosidad_tarde',\n"," 'mm_lluvia_dia',\n"," 'presion_atmosferica_tarde',\n"," 'horas_de_sol',\n"," 'mes',\n"," 'presion_atmosferica_temprano',\n"," 'direccion_viento_temprano_Sursureste']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["columnas_a_usar"]},{"cell_type":"markdown","metadata":{"id":"FsFIZcb60AGa"},"source":["## Búsqueda de hiperparámetros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p27PM-EyysKK"},"outputs":[],"source":["modelo = XGBClassifier()\n","\n","n_estimators = [50, 80]\n","max_depth = [7,10]\n","min_samples_split = [200, 250]\n","min_samples_leaf = [30, 50]\n","max_features = [7, 15]\n","learning_rate = [0.01, 0.1, 0.5]\n","\n","XGB_hyperparameters = dict(n_estimators=n_estimators,\n","                            max_depth=max_depth,\n","                            learning_rate=learning_rate,\n","                            min_samples_split=min_samples_split,\n","                            min_samples_leaf=min_samples_leaf,\n","                            max_features=max_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQ7dZ1566Mls"},"outputs":[],"source":["XGB_hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7181844,"status":"ok","timestamp":1638921293096,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"0nH1JQlky1Ki","outputId":"d1994596-4835-41e3-c72f-027d1196ee5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 96 candidates, totalling 480 fits\n","[12:47:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:47:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.849 total time=   2.5s\n","[12:47:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:47:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.6s\n","[12:47:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.5s\n","[12:47:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:47:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.852 total time=   2.7s\n","[12:48:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.854 total time=   2.7s\n","[12:48:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.851 total time=   4.2s\n","[12:48:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.853 total time=   4.2s\n","[12:48:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.853 total time=   4.2s\n","[12:48:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   4.3s\n","[12:48:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   4.2s\n","[12:48:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.849 total time=   5.1s\n","[12:48:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   5.5s\n","[12:48:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   5.5s\n","[12:48:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.852 total time=   5.5s\n","[12:48:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.854 total time=   5.2s\n","[12:48:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:48:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.851 total time=   7.9s\n","[12:49:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.853 total time=   8.0s\n","[12:49:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.853 total time=   8.2s\n","[12:49:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   7.7s\n","[12:49:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   3.8s\n","[12:49:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.849 total time=   2.5s\n","[12:49:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.7s\n","[12:49:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.7s\n","[12:49:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.852 total time=   2.6s\n","[12:49:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.854 total time=   2.7s\n","[12:49:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.851 total time=   4.2s\n","[12:49:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.853 total time=   5.6s\n","[12:49:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:49:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.853 total time=   8.7s\n","[12:50:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=   8.4s\n","[12:50:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   8.0s\n","[12:50:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.849 total time=   5.0s\n","[12:50:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   5.1s\n","[12:50:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[12:50:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   5.1s\n","[12:50:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.852 total time=   5.0s\n","[12:50:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.854 total time=   4.8s\n","[12:50:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.851 total time=   8.2s\n","[12:50:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.853 total time=   5.3s\n","[12:50:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.853 total time=   3.9s\n","[12:50:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:50:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=   4.2s\n","[12:51:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   4.1s\n","[12:51:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.849 total time=   2.6s\n","[12:51:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.7s\n","[12:51:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.8s\n","[12:51:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.852 total time=   5.7s\n","[12:51:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.854 total time=   5.4s\n","[12:51:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.851 total time=   8.5s\n","[12:51:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.853 total time=   8.0s\n","[12:51:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.853 total time=   7.9s\n","[12:51:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   8.1s\n","[12:51:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:51:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   8.7s\n","[12:52:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.849 total time=   4.8s\n","[12:52:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   5.1s\n","[12:52:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   4.3s\n","[12:52:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.852 total time=   2.5s\n","[12:52:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.854 total time=   2.5s\n","[12:52:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.851 total time=   4.1s\n","[12:52:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.853 total time=   4.2s\n","[12:52:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.853 total time=   4.2s\n","[12:52:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   4.2s\n","[12:52:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   7.7s\n","[12:52:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.849 total time=   5.2s\n","[12:52:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:52:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   5.2s\n","[12:53:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   5.1s\n","[12:53:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.852 total time=   5.0s\n","[12:53:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[12:53:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.854 total time=   5.0s\n","[12:53:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.851 total time=   8.7s\n","[12:53:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.853 total time=   7.8s\n","[12:53:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.853 total time=   7.6s\n","[12:53:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=   7.7s\n","[12:53:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   6.9s\n","[12:53:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.849 total time=   2.5s\n","[12:53:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:53:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   2.5s\n","[12:54:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:54:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   2.6s\n","[12:54:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:54:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.852 total time=   2.6s\n","[12:54:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:54:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.854 total time=   2.7s\n","[12:54:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:54:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.851 total time=   4.2s\n","[12:54:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:54:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.853 total time=   4.2s\n","[12:54:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:54:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.853 total time=   8.0s\n","[12:54:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:54:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=  19.2s\n","[12:54:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:54:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=  18.3s\n","[12:55:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:55:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=  11.4s\n","[12:55:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:55:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   8.3s\n","[12:55:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:55:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.855 total time=   6.1s\n","[12:55:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:55:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.855 total time=   4.1s\n","[12:55:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:55:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.857 total time=   4.2s\n","[12:55:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:55:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   6.8s\n","[12:55:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:55:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   7.8s\n","[12:55:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:55:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=  13.7s\n","[12:56:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:56:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=  13.2s\n","[12:56:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:56:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=  12.9s\n","[12:56:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:56:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   8.1s\n","[12:56:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:56:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=  14.8s\n","[12:56:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:56:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.855 total time=   8.1s\n","[12:57:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:57:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.855 total time=   4.0s\n","[12:57:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:57:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.857 total time=   4.1s\n","[12:57:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:57:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   6.7s\n","[12:57:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:57:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   6.8s\n","[12:57:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:57:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=  13.3s\n","[12:57:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:57:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=  14.2s\n","[12:57:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:57:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=  12.9s\n","[12:58:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:58:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   9.1s\n","[12:58:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:58:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   8.4s\n","[12:58:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:58:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.855 total time=   8.1s\n","[12:58:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:58:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.855 total time=   7.0s\n","[12:58:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:58:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.857 total time=   4.4s\n","[12:58:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:58:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=   6.8s\n","[12:58:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:58:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   6.8s\n","[12:58:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:58:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=  10.3s\n","[12:59:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:59:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=  14.6s\n","[12:59:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:59:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=  16.3s\n","[12:59:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:59:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   8.2s\n","[12:59:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:59:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   8.2s\n","[12:59:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[12:59:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.855 total time=   8.1s\n","[13:00:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:00:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.855 total time=  14.7s\n","[13:00:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:00:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.857 total time=   8.5s\n","[13:00:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:00:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=   9.5s\n","[13:00:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:00:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=  13.5s\n","[13:00:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:00:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=  13.6s\n","[13:00:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:01:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=  13.2s\n","[13:01:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:01:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=  13.9s\n","[13:01:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:01:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   8.2s\n","[13:01:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:01:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   8.2s\n","[13:01:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:01:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.855 total time=   6.1s\n","[13:01:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:01:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.855 total time=   4.0s\n","[13:01:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:01:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.857 total time=   4.2s\n","[13:01:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:01:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   6.9s\n","[13:02:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:02:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   8.3s\n","[13:02:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:02:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=  13.9s\n","[13:02:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:02:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=  27.0s\n","[13:02:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:02:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=  12.9s\n","[13:03:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:03:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   8.1s\n","[13:03:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:03:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   8.7s\n","[13:03:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:03:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.855 total time=   7.3s\n","[13:03:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:03:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.855 total time=   4.1s\n","[13:03:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:03:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.857 total time=   4.2s\n","[13:03:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:03:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   6.8s\n","[13:03:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:03:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   6.8s\n","[13:03:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:03:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=  13.1s\n","[13:04:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:04:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=  13.7s\n","[13:04:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:04:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=  13.4s\n","[13:04:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:04:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   8.1s\n","[13:04:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:04:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   8.3s\n","[13:04:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:04:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.855 total time=   8.1s\n","[13:04:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:04:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.855 total time=   8.1s\n","[13:05:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:05:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.857 total time=   8.1s\n","[13:05:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:05:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=   6.8s\n","[13:05:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:05:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   7.0s\n","[13:05:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:05:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   6.9s\n","[13:05:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:05:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   9.9s\n","[13:05:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:05:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=  13.6s\n","[13:05:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:05:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   8.3s\n","[13:06:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:06:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   8.2s\n","[13:06:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:06:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.855 total time=   8.2s\n","[13:06:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:06:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.855 total time=   8.4s\n","[13:06:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:06:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.857 total time=   8.0s\n","[13:06:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:06:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=  13.1s\n","[13:06:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:06:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=  10.0s\n","[13:07:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:07:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   6.5s\n","[13:07:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:07:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   6.8s\n","[13:07:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:07:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=   9.3s\n","[13:07:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:07:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.866 total time=   5.4s\n","[13:07:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:07:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.868 total time=   5.4s\n","[13:07:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:07:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.865 total time=   5.3s\n","[13:07:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:07:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.867 total time=   5.1s\n","[13:07:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:07:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.869 total time=   8.5s\n","[13:07:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:07:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.868 total time=   8.8s\n","[13:08:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.871 total time=  19.8s\n","[13:08:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.868 total time=  12.3s\n","[13:08:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.869 total time=   5.6s\n","[13:08:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.871 total time=   5.9s\n","[13:08:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.866 total time=   2.7s\n","[13:08:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.868 total time=   2.7s\n","[13:08:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.865 total time=   2.7s\n","[13:08:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.867 total time=   3.8s\n","[13:08:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:08:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.869 total time=   5.4s\n","[13:09:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:09:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.868 total time=   8.4s\n","[13:09:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:09:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.871 total time=   8.1s\n","[13:09:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:09:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.868 total time=   8.3s\n","[13:09:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:09:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.869 total time=   7.9s\n","[13:09:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:09:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.871 total time=   7.9s\n","[13:09:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:09:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.866 total time=   4.9s\n","[13:09:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:09:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.868 total time=   5.1s\n","[13:09:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:09:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.865 total time=   5.0s\n","[13:09:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:09:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.867 total time=   5.0s\n","[13:10:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.869 total time=   5.0s\n","[13:10:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.868 total time=   7.1s\n","[13:10:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.871 total time=   3.8s\n","[13:10:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.868 total time=   3.9s\n","[13:10:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.869 total time=   4.1s\n","[13:10:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.871 total time=   4.1s\n","[13:10:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.866 total time=   2.7s\n","[13:10:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.868 total time=   2.7s\n","[13:10:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.865 total time=   3.6s\n","[13:10:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.867 total time=   5.8s\n","[13:10:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.869 total time=   5.2s\n","[13:10:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:10:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.868 total time=   8.0s\n","[13:11:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.871 total time=   8.1s\n","[13:11:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.868 total time=   8.1s\n","[13:11:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.869 total time=   7.8s\n","[13:11:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.871 total time=   7.7s\n","[13:11:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.866 total time=   4.9s\n","[13:11:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.868 total time=   5.0s\n","[13:11:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:11:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.865 total time=   5.0s\n","[13:11:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.867 total time=   4.9s\n","[13:11:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.869 total time=   4.8s\n","[13:11:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:11:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.868 total time=   5.6s\n","[13:12:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.871 total time=   3.8s\n","[13:12:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.868 total time=   4.0s\n","[13:12:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.869 total time=   4.1s\n","[13:12:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.871 total time=   4.1s\n","[13:12:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.866 total time=   2.7s\n","[13:12:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.868 total time=   3.4s\n","[13:12:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.865 total time=   5.5s\n","[13:12:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.867 total time=   5.5s\n","[13:12:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.869 total time=   5.2s\n","[13:12:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.868 total time=   8.6s\n","[13:12:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.871 total time=   8.0s\n","[13:12:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:12:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.868 total time=   8.1s\n","[13:13:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.869 total time=   9.7s\n","[13:13:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.871 total time=  18.1s\n","[13:13:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.866 total time=   6.7s\n","[13:13:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.868 total time=   2.5s\n","[13:13:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.865 total time=   2.5s\n","[13:13:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.867 total time=   2.6s\n","[13:13:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.869 total time=   2.7s\n","[13:13:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.868 total time=   4.1s\n","[13:13:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.871 total time=   4.2s\n","[13:13:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:13:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.868 total time=   4.2s\n","[13:14:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:14:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.869 total time=   8.5s\n","[13:14:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:14:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.871 total time=   8.1s\n","[13:14:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:14:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.866 total time=   5.3s\n","[13:14:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:14:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.868 total time=   5.3s\n","[13:14:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:14:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.865 total time=   5.1s\n","[13:14:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:14:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.867 total time=   5.2s\n","[13:14:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:14:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.869 total time=   7.9s\n","[13:14:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:14:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.868 total time=   7.9s\n","[13:14:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:14:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.871 total time=   7.5s\n","[13:15:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.868 total time=   7.7s\n","[13:15:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.869 total time=   7.7s\n","[13:15:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.871 total time=   5.9s\n","[13:15:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.866 total time=   3.9s\n","[13:15:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.867 total time=   4.1s\n","[13:15:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.865 total time=   4.2s\n","[13:15:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.867 total time=   4.1s\n","[13:15:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.869 total time=   4.9s\n","[13:15:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.868 total time=  12.9s\n","[13:15:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:15:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.869 total time=  12.5s\n","[13:16:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:16:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.867 total time=  12.3s\n","[13:16:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:16:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.867 total time=  12.0s\n","[13:16:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:16:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.870 total time=  12.0s\n","[13:16:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:16:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.866 total time=   7.6s\n","[13:16:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:16:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.867 total time=   3.9s\n","[13:16:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:16:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.865 total time=   4.0s\n","[13:17:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:17:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.867 total time=   4.2s\n","[13:17:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:17:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.869 total time=   4.2s\n","[13:17:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:17:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.868 total time=   7.5s\n","[13:17:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:17:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.869 total time=  12.8s\n","[13:17:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:17:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.867 total time=  12.4s\n","[13:17:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:17:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.867 total time=  12.2s\n","[13:17:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:17:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.870 total time=  12.1s\n","[13:18:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:18:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.866 total time=   7.9s\n","[13:18:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:18:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.867 total time=   8.0s\n","[13:18:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:18:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.865 total time=   8.5s\n","[13:18:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:18:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.867 total time=   9.3s\n","[13:18:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:18:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.869 total time=   6.9s\n","[13:18:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:18:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.868 total time=   6.4s\n","[13:18:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:18:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.869 total time=  11.0s\n","[13:19:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:19:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.867 total time=  12.5s\n","[13:19:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:19:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.867 total time=  12.4s\n","[13:19:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:19:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.870 total time=  12.2s\n","[13:19:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:19:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.866 total time=   7.9s\n","[13:19:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:19:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.867 total time=   8.1s\n","[13:19:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:20:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.865 total time=   8.5s\n","[13:20:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:20:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.867 total time=   7.5s\n","[13:20:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:20:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.869 total time=   3.9s\n","[13:20:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:20:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.868 total time=   6.2s\n","[13:20:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:20:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.869 total time=   6.3s\n","[13:20:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:20:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.867 total time=   6.3s\n","[13:20:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:20:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.867 total time=  24.6s\n","[13:21:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:21:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.870 total time=  12.2s\n","[13:21:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:21:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.866 total time=   8.7s\n","[13:21:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:21:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.867 total time=   7.7s\n","[13:21:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:21:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.865 total time=   7.8s\n","[13:21:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:21:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.867 total time=   7.7s\n","[13:21:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:21:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.869 total time=   5.8s\n","[13:21:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:21:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.868 total time=   6.1s\n","[13:21:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:21:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.869 total time=   6.3s\n","[13:22:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:22:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.867 total time=   6.3s\n","[13:22:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:22:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.867 total time=  11.8s\n","[13:22:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:22:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.870 total time=  12.7s\n","[13:22:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:22:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.866 total time=   8.1s\n","[13:22:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:22:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.867 total time=   8.4s\n","[13:22:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:22:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.865 total time=   8.2s\n","[13:23:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:23:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.867 total time=   7.8s\n","[13:23:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:23:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.869 total time=   7.8s\n","[13:23:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:23:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.868 total time=  12.5s\n","[13:23:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:23:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.869 total time=   6.1s\n","[13:23:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:23:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.867 total time=   6.2s\n","[13:23:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:23:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.867 total time=   7.9s\n","[13:23:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:23:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.870 total time=   9.8s\n","[13:23:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:23:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.866 total time=   8.6s\n","[13:24:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:24:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.867 total time=   8.3s\n","[13:24:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:24:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.865 total time=   8.3s\n","[13:24:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:24:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.867 total time=   7.9s\n","[13:24:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:24:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.869 total time=   7.8s\n","[13:24:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:24:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.868 total time=  13.4s\n","[13:24:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:24:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.869 total time=  11.8s\n","[13:25:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:25:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.867 total time=   7.3s\n","[13:25:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:25:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.867 total time=   6.1s\n","[13:25:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:25:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.870 total time=   6.7s\n","[13:25:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:25:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.866 total time=   4.7s\n","[13:25:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:25:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.867 total time=   8.6s\n","[13:25:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:25:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.865 total time=   8.2s\n","[13:25:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:25:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.867 total time=  11.5s\n","[13:25:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:25:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.869 total time=   8.3s\n","[13:26:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:26:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.868 total time=  12.2s\n","[13:26:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:26:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.869 total time=  12.1s\n","[13:26:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:26:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.867 total time=  12.0s\n","[13:26:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:26:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.867 total time=   9.5s\n","[13:26:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:26:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.870 total time=   6.0s\n","[13:26:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:26:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   2.6s\n","[13:27:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.859 total time=   2.6s\n","[13:27:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.856 total time=   2.6s\n","[13:27:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   2.6s\n","[13:27:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.855 total time=   2.6s\n","[13:27:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   8.3s\n","[13:27:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.857 total time=   8.2s\n","[13:27:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   8.0s\n","[13:27:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.857 total time=   7.9s\n","[13:27:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.852 total time=   7.8s\n","[13:27:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   4.8s\n","[13:27:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:27:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.859 total time=   4.8s\n","[13:28:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:28:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.856 total time=   4.7s\n","[13:28:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   5.1s\n","[13:28:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.855 total time=   5.0s\n","[13:28:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   7.5s\n","[13:28:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.857 total time=   7.1s\n","[13:28:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   4.2s\n","[13:28:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.857 total time=   3.9s\n","[13:28:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.852 total time=   4.1s\n","[13:28:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   2.8s\n","[13:28:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.859 total time=   2.6s\n","[13:28:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.856 total time=   2.7s\n","[13:28:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   4.1s\n","[13:28:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:28:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.855 total time=   5.1s\n","[13:29:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:29:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   8.2s\n","[13:29:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:29:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.857 total time=   7.9s\n","[13:29:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:29:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=  10.3s\n","[13:29:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:29:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.857 total time=   7.5s\n","[13:29:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:29:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.852 total time=   7.7s\n","[13:29:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:29:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   4.8s\n","[13:29:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:29:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.859 total time=   5.0s\n","[13:29:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:29:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.856 total time=   5.0s\n","[13:29:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:29:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   4.9s\n","[13:30:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.855 total time=   4.9s\n","[13:30:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   6.3s\n","[13:30:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.857 total time=   3.8s\n","[13:30:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=   3.9s\n","[13:30:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.857 total time=   4.0s\n","[13:30:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.852 total time=   4.1s\n","[13:30:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   2.6s\n","[13:30:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.859 total time=   2.6s\n","[13:30:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.856 total time=   3.8s\n","[13:30:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   5.2s\n","[13:30:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.855 total time=   5.7s\n","[13:30:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   8.0s\n","[13:30:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:30:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.857 total time=   8.0s\n","[13:31:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   7.8s\n","[13:31:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.857 total time=   7.8s\n","[13:31:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.852 total time=   7.9s\n","[13:31:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   4.8s\n","[13:31:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.859 total time=   4.8s\n","[13:31:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.856 total time=   4.8s\n","[13:31:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   4.9s\n","[13:31:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:31:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.855 total time=   4.9s\n","[13:31:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   5.8s\n","[13:31:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:31:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.857 total time=   3.8s\n","[13:32:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   3.9s\n","[13:32:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.857 total time=   4.0s\n","[13:32:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.852 total time=   4.1s\n","[13:32:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   2.8s\n","[13:32:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.859 total time=   5.4s\n","[13:32:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.856 total time=   5.2s\n","[13:32:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   4.9s\n","[13:32:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.855 total time=   4.9s\n","[13:32:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   8.0s\n","[13:32:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.857 total time=   8.0s\n","[13:32:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:32:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=   7.5s\n","[13:33:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.857 total time=   7.6s\n","[13:33:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.852 total time=   7.7s\n","[13:33:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   5.0s\n","[13:33:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.859 total time=   4.9s\n","[13:33:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.856 total time=   4.7s\n","[13:33:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   4.5s\n","[13:33:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.855 total time=   2.4s\n","[13:33:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   3.8s\n","[13:33:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.857 total time=   4.0s\n","[13:33:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=   4.1s\n","[13:33:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.857 total time=   4.0s\n","[13:33:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.852 total time=   4.1s\n","[13:33:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:33:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.850 total time=   7.0s\n","[13:34:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:34:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   8.0s\n","[13:34:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:34:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.854 total time=   8.0s\n","[13:34:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:34:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   7.8s\n","[13:34:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:34:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   7.4s\n","[13:34:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:34:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.851 total time=  12.2s\n","[13:34:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:34:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.853 total time=  11.5s\n","[13:34:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:34:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.855 total time=  11.6s\n","[13:35:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:35:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.852 total time=  10.1s\n","[13:35:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:35:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.853 total time=   5.7s\n","[13:35:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:35:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.850 total time=   3.9s\n","[13:35:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:35:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   3.9s\n","[13:35:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:35:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.854 total time=   3.9s\n","[13:35:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:35:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   3.9s\n","[13:35:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:35:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   8.1s\n","[13:35:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:35:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.851 total time=  12.3s\n","[13:36:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:36:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.853 total time=  11.8s\n","[13:36:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:36:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.855 total time=  11.7s\n","[13:36:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:36:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.852 total time=  11.6s\n","[13:36:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:36:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.853 total time=  11.8s\n","[13:36:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:36:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.850 total time=   7.1s\n","[13:36:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:36:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   6.1s\n","[13:37:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:37:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.854 total time=   3.6s\n","[13:37:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:37:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   3.8s\n","[13:37:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:37:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   3.9s\n","[13:37:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:37:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.851 total time=   6.0s\n","[13:37:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:37:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.853 total time=   9.6s\n","[13:37:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:37:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.855 total time=  12.3s\n","[13:37:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:37:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.852 total time=  12.1s\n","[13:37:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:37:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.853 total time=  11.8s\n","[13:38:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:38:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.850 total time=   7.3s\n","[13:38:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:38:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   7.3s\n","[13:38:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:38:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.854 total time=   7.2s\n","[13:38:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:38:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   7.2s\n","[13:38:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:38:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   7.1s\n","[13:38:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:38:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.851 total time=   5.9s\n","[13:38:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:38:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.853 total time=   6.0s\n","[13:38:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:38:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.855 total time=   6.2s\n","[13:39:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:39:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.852 total time=   7.8s\n","[13:39:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:39:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.853 total time=  12.4s\n","[13:39:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:39:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.850 total time=   8.2s\n","[13:39:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:39:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   7.7s\n","[13:39:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:39:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.854 total time=   7.4s\n","[13:39:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:39:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   7.6s\n","[13:39:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:39:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   7.2s\n","[13:39:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:39:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.851 total time=  11.6s\n","[13:40:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:40:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.853 total time=   9.3s\n","[13:40:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:40:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.855 total time=   5.8s\n","[13:40:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:40:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.852 total time=   6.1s\n","[13:40:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:40:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.853 total time=   6.1s\n","[13:40:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:40:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.850 total time=   8.5s\n","[13:40:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:40:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   7.9s\n","[13:40:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:40:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.854 total time=   7.5s\n","[13:41:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:41:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   7.7s\n","[13:41:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:41:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   7.4s\n","[13:41:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:41:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.851 total time=  11.8s\n","[13:41:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:41:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.853 total time=  11.3s\n","[13:41:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:41:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.855 total time=  11.5s\n","[13:41:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:41:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.852 total time=   6.7s\n","[13:41:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:41:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.853 total time=   5.9s\n","[13:42:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:42:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.850 total time=   3.9s\n","[13:42:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:42:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   3.9s\n","[13:42:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:42:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.854 total time=   3.9s\n","[13:42:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:42:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   6.6s\n","[13:42:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:42:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   7.8s\n","[13:42:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:42:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.851 total time=  12.1s\n","[13:42:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:42:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.853 total time=  12.2s\n","[13:42:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:42:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.855 total time=  11.7s\n","[13:43:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:43:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.852 total time=  11.7s\n","[13:43:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:43:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.853 total time=  12.2s\n","[13:43:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[13:43:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.850 total time=   7.1s\n","[13:43:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:43:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   4.1s\n","[13:43:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:43:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.854 total time=   3.7s\n","[13:43:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:43:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   3.9s\n","[13:43:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:43:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   3.9s\n","[13:43:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:43:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.851 total time=   6.1s\n","[13:43:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:43:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.853 total time=  11.9s\n","[13:44:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:44:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.855 total time=  12.1s\n","[13:44:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:44:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.852 total time=  11.9s\n","[13:44:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:44:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.853 total time=  12.2s\n","[13:44:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:44:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["GridSearchCV(cv=5,\n","             estimator=XGBClassifier(base_score=None, booster=None,\n","                                     colsample_bylevel=None,\n","                                     colsample_bynode=None,\n","                                     colsample_bytree=None,\n","                                     enable_categorical=False, gamma=None,\n","                                     gpu_id=None, importance_type=None,\n","                                     interaction_constraints=None,\n","                                     learning_rate=None, max_delta_step=None,\n","                                     max_depth=None, min_child_weight=None,\n","                                     missing=nan, monotone_constraints=None,...\n","                                     num_parallel_tree=None, predictor=None,\n","                                     random_state=None, reg_alpha=None,\n","                                     reg_lambda=None, scale_pos_weight=None,\n","                                     subsample=None, tree_method=None,\n","                                     validate_parameters=None, verbosity=None),\n","             param_grid={'learning_rate': [0.01, 0.1, 0.5],\n","                         'max_depth': [7, 10], 'max_features': [7, 15],\n","                         'min_samples_leaf': [30, 50],\n","                         'min_samples_split': [200, 250],\n","                         'n_estimators': [50, 80]},\n","             scoring='roc_auc', verbose=4)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["xgbsearch = GridSearchCV(estimator=modelo, param_grid=XGB_hyperparameters, cv=5, verbose=4, scoring='roc_auc')\n","xgbsearch.fit(hamburguesas_train_values_ht, hamburguesas_train_target_enc)#eval_metric='roc_auc'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1638921351393,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"6bDR-QAqzVyJ","outputId":"d351de0a-4a82-43dd-9529-1e372e8499f2"},"outputs":[{"data":{"text/plain":["{'learning_rate': 0.1,\n"," 'max_depth': 7,\n"," 'max_features': 7,\n"," 'min_samples_leaf': 30,\n"," 'min_samples_split': 200,\n"," 'n_estimators': 80}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["parametros = xgbsearch.best_params_\n","parametros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYCW_a5E6Mly","outputId":"0c50b2c4-79a0-4153-f82c-29e638cc3595"},"outputs":[{"data":{"text/plain":["0.8692978954594415"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["xgbsearch.best_score_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeVUK_286Mlz"},"outputs":[],"source":["parametros = {'learning_rate': 0.1,\n","              'max_depth': 7,\n","              'max_features': 7,\n","              'min_samples_leaf': 30,\n","              'min_samples_split': 200,\n","              'n_estimators': 80}"]},{"cell_type":"markdown","metadata":{"id":"5aMdO25MCr1O"},"source":["Como ya encontramos los mejores hiperparámetros, creamos un diccionario con dichos valores (esto es para cuando no podamos hacer el `.best_params_` porque no ejecutamos GridSearch cuando usamos el notebook otro día debido al tiempo que insume)"]},{"cell_type":"markdown","metadata":{"id":"k1-aFcxe1g2e"},"source":["## Entrenamos y vemos cómo nos va"]},{"cell_type":"markdown","metadata":{"id":"smkZltvQJnJe"},"source":["Vemos qué pasa si separamos así nomas al `df_reducido` en 5. Para eso vemos las proporciones:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6690,"status":"ok","timestamp":1639017359641,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"arC9z6OM1gIT","outputId":"154ed7af-6816-4b9b-dbf0-453a9aeeba3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[13:48:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[13:48:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n","              gamma=0, gpu_id=-1, importance_type=None,\n","              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n","              max_depth=7, max_features=7, min_child_weight=1,\n","              min_samples_leaf=30, min_samples_split=200, missing=nan,\n","              monotone_constraints='()', n_estimators=80, n_jobs=8,\n","              num_parallel_tree=1, predictor='auto', random_state=0,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n","              tree_method='exact', validate_parameters=1, ...)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["modelo = XGBClassifier(**parametros)\n","modelo.fit(hamburguesas_train_values_ht, hamburguesas_train_target_enc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mo8xvaFuYd0A"},"outputs":[],"source":["prediccion = modelo.predict_proba(hamburguesas_val_dev_values_ht)[:,1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":250,"status":"ok","timestamp":1639017429380,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"TnzfX6qTzWMR","outputId":"e379ed3c-bc92-47e8-ba51-af06b7f86cef"},"outputs":[{"data":{"text/plain":["0.8700893215229195"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["roc_auc_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fK-Nr8aP6Ml9"},"outputs":[],"source":["prediccion = modelo.predict(hamburguesas_val_dev_values_ht)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1639017431718,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"7DXH9khvYakI","outputId":"f09f9583-e358-4d53-ab92-63b6f49994b0"},"outputs":[{"data":{"text/plain":["0.8487814193301984"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["accuracy_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1639017433089,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"5sFOPzhDY_BX","outputId":"dd2bcef7-10e2-4fa4-f1c4-371cdffab665"},"outputs":[{"data":{"text/plain":["0.5034384892478987"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["recall_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1639017435284,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"N7uzxOhZZCi3","outputId":"0b6189c5-60ad-433a-890a-1a34993ba30e"},"outputs":[{"data":{"text/plain":["0.7208502657080338"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["precision_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1639017453508,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"GEMa-O16DH4H","outputId":"4d055ac0-4aa9-408a-b4f2-817a80fbd599"},"outputs":[{"data":{"text/plain":["0.5928401568224179"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["f1_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1639017505934,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"1ubIJ1TtZKwu","outputId":"ae60ce78-2504-4f1f-c32f-005ea8112226"},"outputs":[{"data":{"text/plain":["{'tn': 30946, 'fp': 1786, 'fn': 4549, 'tp': 4612}"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["cm = confusion_matrix(hamburguesas_val_dev_target_enc, prediccion)\n","{'tn': cm[0, 0], 'fp': cm[0, 1],\n","'fn': cm[1, 0], 'tp': cm[1, 1]}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbCjdSub6MmF","outputId":"02e029ab-21c6-494d-f257-99127faef135"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 448x336 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=modelo.classes_)\n","disp.plot()\n","plt.show()"]},{"cell_type":"markdown","source":["La matriz de confusion nos muestra nuestros $tp$ (verdaderos positivos, arriba a la izquierda), $fp$ (falsos positivos, abajo a la izquierda), $tn$ (verdaderos negativos, abajo a la derecha) y $fn$ (falsos negativos, arriba a la derecha) en una matriz."],"metadata":{"id":"LuFKeTtCe8MY"}},{"cell_type":"markdown","source":["En este caso, la tendencia del modelo es que tiende a predecir 0 sobre 1 porque si vemos la otra diagonal (la de \"pifiadas\") vemos que hay más casos de era 1 y lo predijo como 0, respecto de era 0 y lo predijo como 1. Por otro lado, la diagonal principal, es \"saludable\", pues hay una diferencia muy alta entre los casos en los que era 0 y predijo 0 respecto de los de la otra diagonal y lo mismo ocurrió en los casos en los que era 1 y predijo 1 pero con una diferencia no tan notoria. "],"metadata":{"id":"TMnF0i0Ze9pm"}},{"cell_type":"markdown","source":["El modelo predijo bien más positivos (35495 casos, 84,73%) que negativos (6398 casos, 15,27%) porque hay una gran cantidad de verdaderos positivos y (en menor medida) falsos positivos, mientras que los verdaderos negativos y falsos negativos hay menos."],"metadata":{"id":"e8hxv0Raf14Y"}},{"cell_type":"markdown","metadata":{"id":"LOXmunmtnyu6"},"source":["## Predicciones"]},{"cell_type":"markdown","metadata":{"id":"J079FK-LD2xI"},"source":["Dado que salvo en uno de los folds, en el resto de ellos se obtuvo mejor score del auc con Hashing trick que en Binary encoding; el ganador para hacer la predicción es el modelo de esta sección (el mejor modelo de su mismo tipo)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33Yh842Mn0Xd"},"outputs":[],"source":["hamburguesas_test_ohe = preprocessing_knn_imputer_robust_escaler_one_hot_encoding_hashing_trick(\n","    None,\n","    None,\n","    None,\n","    hamburguesas_test,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OU6sOSfwpZPJ"},"outputs":[],"source":["predicciones = modelo.predict(hamburguesas_test_ohe)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V04d-iCV5GSt"},"outputs":[],"source":["auxiliar = hamburguesas_test.join(hamburguesas_target).reset_index()\n","auxiliar = auxiliar[['id', 'llovieron_hamburguesas_al_dia_siguiente']]\n","auxiliar = auxiliar.set_index('id')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DtDdd9tIsqWD"},"outputs":[],"source":["nuestra_prediccion = pd.DataFrame(data=predicciones, columns=auxiliar.columns, index=auxiliar.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejUXe38M3H1M"},"outputs":[],"source":["for v in nuestra_prediccion.columns:\n","  nuestra_prediccion.loc[:, v] = nuestra_prediccion[v].map({0: 'no', 1: 'si',})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbF8BcPs6MmN"},"outputs":[],"source":["nuestra_prediccion.to_csv('XGBoost_knn_imputer_robust_escaler_one_hot_encoding_hashing_trick.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WwrlDBea2He7"},"outputs":[],"source":["nuestra_prediccion.to_csv('/drive/My Drive/TP_Datos_2C2021/parte_2/XGBoost.csv')"]},{"cell_type":"markdown","metadata":{"id":"dcl3oT9mW2tn"},"source":["# Mean imputer, standar scaler, one hot encoding y binary encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbAa7CAUW4-A"},"outputs":[],"source":["hamburguesas_train_values_bin, hamburguesas_val_dev_values_bin, X_test_holdout_sn = preprocessing_mean_imputer_standar_escaler_one_hot_encoding_binary_encoding(\n","    X_train, \n","    X_val_dev, \n","    X_test_holdout\n",")\n","\n","hamburguesas_train_target_enc = y_train['llovieron_hamburguesas_al_dia_siguiente'].map({'no': 0, 'si': 1, np.NaN: 0})\n","hamburguesas_val_dev_target_enc = y_val_dev['llovieron_hamburguesas_al_dia_siguiente'].map({'no': 0, 'si': 1, np.NaN: 0})"]},{"cell_type":"markdown","metadata":{"id":"cSZ22TTUXPA3"},"source":["## Selección de features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7737,"status":"ok","timestamp":1639017976132,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"eBTLXRciXQGO","outputId":"251cc08c-2ca8-41f4-b668-755c77bbec90"},"outputs":[{"name":"stdout","output_type":"stream","text":["[17:08:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n","              gamma=0, gpu_id=-1, importance_type=None,\n","              interaction_constraints='', learning_rate=0.300000012,\n","              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n","              monotone_constraints='()', n_estimators=100, n_jobs=8,\n","              num_parallel_tree=1, predictor='auto', random_state=0,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n","              tree_method='exact', validate_parameters=1, verbosity=None)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["modelo = XGBClassifier()\n","modelo.fit(hamburguesas_train_values_bin, hamburguesas_train_target_enc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"brUedMe9XWhX"},"outputs":[],"source":["importancia = []\n","for i in range (len(modelo.feature_importances_)):\n","  importancia.append((modelo.feature_importances_[i], hamburguesas_train_values_bin.columns[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1639017979269,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"d6Pe2jshXeUJ","outputId":"9c5cee0f-1342-438f-fc4e-12a94666d2f3"},"outputs":[{"data":{"text/plain":["[(0.18901691, 'humedad_tarde'),\n"," (0.041785985, 'rafaga_viento_max_velocidad'),\n"," (0.03711973, 'horas_de_sol'),\n"," (0.03258285, 'nubosidad_tarde'),\n"," (0.029325513, 'mm_lluvia_dia'),\n"," (0.027020514, 'presion_atmosferica_temprano'),\n"," (0.016574595, 'mes'),\n"," (0.0152434455, 'presion_atmosferica_tarde'),\n"," (0.015183459, 'rafaga_viento_max_direccion_Noreste'),\n"," (0.014435604, 'temp_max'),\n"," (0.013943291, 'rafaga_viento_max_direccion_Este'),\n"," (0.013817117, 'direccion_viento_tarde_Sursuroeste'),\n"," (0.013549162, 'velocidad_viendo_tarde'),\n"," (0.013533298, 'rafaga_viento_max_direccion_Oeste'),\n"," (0.013356597, 'temperatura_temprano'),\n"," (0.013288351, 'temperatura_tarde'),\n"," (0.013282294, 'rafaga_viento_max_direccion_Noroeste'),\n"," (0.013096754, 'nubosidad_temprano'),\n"," (0.013070272, 'direccion_viento_tarde_Sursureste'),\n"," (0.012761935, 'humedad_temprano'),\n"," (0.012484025, 'direccion_viento_temprano_Nornoreste'),\n"," (0.012455946, 'temp_min'),\n"," (0.012186382, 'rafaga_viento_max_direccion_Sur'),\n"," (0.012185558, 'velocidad_viendo_temprano'),\n"," (0.011376144, 'mm_evaporados_agua'),\n"," (0.011357468, 'direccion_viento_tarde_Oestenoroeste'),\n"," (0.011355086, 'barrio_0'),\n"," (0.011175185, 'direccion_viento_tarde_Sur'),\n"," (0.01109741, 'direccion_viento_temprano_Sur'),\n"," (0.010982451, 'direccion_viento_temprano_Noroeste'),\n"," (0.010824174, 'rafaga_viento_max_direccion_Suroeste'),\n"," (0.010653564, 'direccion_viento_tarde_Noreste'),\n"," (0.01062928, 'llovieron_hamburguesas_hoy_No'),\n"," (0.010511951, 'direccion_viento_temprano_Oestesuroeste'),\n"," (0.010448692, 'direccion_viento_tarde_Estenoreste'),\n"," (0.010402137, 'rafaga_viento_max_direccion_Sursureste'),\n"," (0.010241464, 'direccion_viento_temprano_Sureste'),\n"," (0.010123847, 'rafaga_viento_max_direccion_Estenoreste'),\n"," (0.010092163, 'rafaga_viento_max_direccion_Nornoreste'),\n"," (0.01000194, 'direccion_viento_tarde_Oestesuroeste'),\n"," (0.0098994905, 'dia'),\n"," (0.00973589, 'rafaga_viento_max_direccion_Oestesuroeste'),\n"," (0.009710179, 'direccion_viento_temprano_Sursuroeste'),\n"," (0.009667288, 'llovieron_hamburguesas_hoy_Si'),\n"," (0.009621483, 'direccion_viento_tarde_Este'),\n"," (0.009535642, 'anio'),\n"," (0.00935522, 'direccion_viento_temprano_Sursureste'),\n"," (0.0092098145, 'direccion_viento_tarde_Suroeste'),\n"," (0.009007259, 'barrio_2'),\n"," (0.008412336, 'rafaga_viento_max_direccion_Estesureste'),\n"," (0.00840513, 'direccion_viento_tarde_Oeste'),\n"," (0.008301041, 'barrio_3'),\n"," (0.008233281, 'rafaga_viento_max_direccion_Norte'),\n"," (0.007963035, 'direccion_viento_tarde_Estesureste'),\n"," (0.007961748, 'direccion_viento_tarde_Nornoreste'),\n"," (0.00783519, 'direccion_viento_temprano_Oestenoroeste'),\n"," (0.0077568805, 'direccion_viento_temprano_Norte'),\n"," (0.007695359, 'barrio_1'),\n"," (0.0076880655, 'direccion_viento_tarde_Norte'),\n"," (0.007681548, 'rafaga_viento_max_direccion_Oestenoroeste'),\n"," (0.0076248553, 'direccion_viento_temprano_Suroeste'),\n"," (0.0074390885, 'barrio_4'),\n"," (0.0071742046, 'direccion_viento_tarde_Noroeste'),\n"," (0.0071069114, 'rafaga_viento_max_direccion_Sureste'),\n"," (0.007096682, 'direccion_viento_temprano_Este'),\n"," (0.0070632035, 'direccion_viento_temprano_Oeste'),\n"," (0.006850006, 'direccion_viento_tarde_Sureste'),\n"," (0.0033966273, 'direccion_viento_temprano_Estesureste'),\n"," (0.0, 'rafaga_viento_max_direccion_Sursuroeste'),\n"," (0.0, 'direccion_viento_temprano_Noreste'),\n"," (0.0, 'direccion_viento_temprano_Estenoreste')]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["importancia.sort(reverse=True)\n","importancia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hU-hjne_Xijg"},"outputs":[],"source":["aux = importancia[:9] #puede variar\n","columnas_a_usar = []\n","for tupla in aux:\n","  columnas_a_usar.append(tupla[1])"]},{"cell_type":"markdown","metadata":{"id":"qBe1O3E-6MmX"},"source":["Esto es para KNN ya que ese modelo no es lo suficientemente inteligente para saber a qué columnas le debe dar más imporatancia"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1639017983605,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"SjaebNouaeqa","outputId":"2a8994f5-4090-4450-b1dc-82f4b3e5564b"},"outputs":[{"data":{"text/plain":["['humedad_tarde',\n"," 'rafaga_viento_max_velocidad',\n"," 'horas_de_sol',\n"," 'nubosidad_tarde',\n"," 'mm_lluvia_dia',\n"," 'presion_atmosferica_temprano',\n"," 'mes',\n"," 'presion_atmosferica_tarde',\n"," 'rafaga_viento_max_direccion_Noreste']"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["columnas_a_usar"]},{"cell_type":"markdown","metadata":{"id":"JMtIlC4iakBh"},"source":["## Búsqueda de hiperparámetros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyGYrFwfZ-Ph"},"outputs":[],"source":["modelo = XGBClassifier()\n","\n","n_estimators = [50, 80]\n","max_depth = [7,10]\n","min_samples_split = [200, 250]\n","min_samples_leaf = [30, 50]\n","max_features = [7, 15]\n","learning_rate = [0.01, 0.1, 0.5]\n","\n","XGB_hyperparameters = dict(n_estimators=n_estimators,\n","                            max_depth=max_depth,\n","                            learning_rate=learning_rate,\n","                            min_samples_split=min_samples_split,\n","                            min_samples_leaf=min_samples_leaf,\n","                            max_features=max_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_rXzyT86Mmc","outputId":"b988bd88-4df0-4d48-8efa-da8c5feebc46"},"outputs":[{"data":{"text/plain":["{'n_estimators': [50, 80],\n"," 'max_depth': [7, 10],\n"," 'learning_rate': [0.01, 0.1, 0.5],\n"," 'min_samples_split': [200, 250],\n"," 'min_samples_leaf': [30, 50],\n"," 'max_features': [7, 15]}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["XGB_hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7170186,"status":"ok","timestamp":1638930111379,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"55j4Tn8TaE1J","outputId":"e8dc1030-04fe-4908-fc31-be176ae6ef46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 96 candidates, totalling 480 fits\n","[18:01:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   3.3s\n","[18:01:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   2.5s\n","[18:01:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.5s\n","[18:01:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   2.6s\n","[18:01:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.855 total time=   2.7s\n","[18:01:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   4.2s\n","[18:01:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   4.2s\n","[18:01:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   4.3s\n","[18:01:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   4.2s\n","[18:01:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.857 total time=   4.2s\n","[18:01:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   2.7s\n","[18:01:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   2.7s\n","[18:01:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   2.7s\n","[18:01:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:01:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   6.2s\n","[18:02:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.855 total time=   2.5s\n","[18:02:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   4.2s\n","[18:02:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   4.3s\n","[18:02:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   4.3s\n","[18:02:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   8.2s\n","[18:02:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.857 total time=   8.8s\n","[18:02:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   5.2s\n","[18:02:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:02:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   5.3s\n","[18:02:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   5.1s\n","[18:02:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   5.2s\n","[18:02:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:02:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.855 total time=   5.2s\n","[18:03:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   5.2s\n","[18:03:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   3.9s\n","[18:03:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=   4.2s\n","[18:03:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   4.2s\n","[18:03:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.857 total time=   4.4s\n","[18:03:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   2.7s\n","[18:03:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   2.7s\n","[18:03:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   2.8s\n","[18:03:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   6.9s\n","[18:03:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.855 total time=   5.3s\n","[18:03:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   8.4s\n","[18:03:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:03:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   8.2s\n","[18:04:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=   8.5s\n","[18:04:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   8.0s\n","[18:04:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.857 total time=   5.8s\n","[18:04:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   2.5s\n","[18:04:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   2.5s\n","[18:04:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.7s\n","[18:04:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.853 total time=   2.7s\n","[18:04:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.855 total time=   2.7s\n","[18:04:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   4.2s\n","[18:04:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   4.2s\n","[18:04:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   4.2s\n","[18:04:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.856 total time=   7.6s\n","[18:04:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:04:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.857 total time=   8.7s\n","[18:05:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   5.2s\n","[18:05:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   5.1s\n","[18:05:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.851 total time=   5.4s\n","[18:05:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:05:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.853 total time=   5.0s\n","[18:05:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.855 total time=   5.0s\n","[18:05:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   8.0s\n","[18:05:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   7.3s\n","[18:05:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   3.9s\n","[18:05:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.856 total time=   4.0s\n","[18:05:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.857 total time=   4.2s\n","[18:05:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:05:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   2.7s\n","[18:06:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   2.9s\n","[18:06:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.851 total time=   2.7s\n","[18:06:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.853 total time=   2.7s\n","[18:06:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.855 total time=   4.3s\n","[18:06:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   6.5s\n","[18:06:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   8.4s\n","[18:06:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=   8.2s\n","[18:06:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.856 total time=   9.5s\n","[18:06:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.857 total time=   8.0s\n","[18:06:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:06:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   5.1s\n","[18:07:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   5.1s\n","[18:07:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.851 total time=   4.9s\n","[18:07:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.853 total time=   2.6s\n","[18:07:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.855 total time=   2.5s\n","[18:07:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   4.1s\n","[18:07:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   4.3s\n","[18:07:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=   4.2s\n","[18:07:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.856 total time=   4.2s\n","[18:07:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.857 total time=   4.2s\n","[18:07:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   7.1s\n","[18:07:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.9s\n","[18:07:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:07:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.856 total time=   8.3s\n","[18:08:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:08:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.859 total time=   8.7s\n","[18:08:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:08:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.859 total time=   8.3s\n","[18:08:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:08:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.862 total time=  12.8s\n","[18:08:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:08:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.861 total time=   9.2s\n","[18:08:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:08:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.858 total time=   6.6s\n","[18:08:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:08:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.861 total time=   6.8s\n","[18:08:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:08:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=   6.7s\n","[18:09:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:09:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   5.5s\n","[18:09:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:09:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.8s\n","[18:09:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:09:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.856 total time=   8.4s\n","[18:09:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:09:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.859 total time=   8.4s\n","[18:09:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:09:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.859 total time=   8.2s\n","[18:09:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:09:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.862 total time=  13.2s\n","[18:09:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:09:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.861 total time=   8.6s\n","[18:10:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:10:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.858 total time=   6.8s\n","[18:10:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:10:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.861 total time=   6.7s\n","[18:10:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:10:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=   6.7s\n","[18:10:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:10:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.3s\n","[18:10:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:10:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.7s\n","[18:10:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:10:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.856 total time=   8.2s\n","[18:10:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:10:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.859 total time=   8.2s\n","[18:10:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:10:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.859 total time=   8.2s\n","[18:11:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:11:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.862 total time=  13.3s\n","[18:11:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:11:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.861 total time=   9.4s\n","[18:11:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:11:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.858 total time=  11.4s\n","[18:11:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:11:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.861 total time=  16.8s\n","[18:11:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:11:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=  13.9s\n","[18:12:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:12:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.3s\n","[18:12:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:12:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.2s\n","[18:12:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:12:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.856 total time=   8.1s\n","[18:12:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:12:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.859 total time=   8.3s\n","[18:12:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:12:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.859 total time=   5.3s\n","[18:12:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:12:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.862 total time=   6.5s\n","[18:12:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:12:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.861 total time=   6.7s\n","[18:12:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:12:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.858 total time=   6.7s\n","[18:13:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:13:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.861 total time=  10.4s\n","[18:13:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:13:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=  14.0s\n","[18:13:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:13:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.2s\n","[18:13:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:13:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.1s\n","[18:13:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:13:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.856 total time=   8.4s\n","[18:13:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:13:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.859 total time=   8.0s\n","[18:14:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:14:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.859 total time=   5.3s\n","[18:14:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:14:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.862 total time=   6.5s\n","[18:14:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:14:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.861 total time=   6.8s\n","[18:14:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:14:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.858 total time=   6.7s\n","[18:14:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:14:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.861 total time=  13.2s\n","[18:14:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:14:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=  19.3s\n","[18:15:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:15:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.2s\n","[18:15:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:15:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.3s\n","[18:15:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:15:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.856 total time=   8.5s\n","[18:15:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:15:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.859 total time=   4.9s\n","[18:15:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:15:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.859 total time=   4.0s\n","[18:15:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:15:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.862 total time=   6.7s\n","[18:15:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:15:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.861 total time=   6.7s\n","[18:15:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:15:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.858 total time=   8.3s\n","[18:15:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:15:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.861 total time=  14.1s\n","[18:16:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:16:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=  13.0s\n","[18:16:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:16:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.2s\n","[18:16:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:16:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.4s\n","[18:16:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:16:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.856 total time=   8.0s\n","[18:16:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:16:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.859 total time=   7.1s\n","[18:16:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:16:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.859 total time=   4.0s\n","[18:16:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:16:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.862 total time=   6.6s\n","[18:17:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:17:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.861 total time=   6.8s\n","[18:17:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:17:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.858 total time=   8.1s\n","[18:17:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:17:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.861 total time=  14.2s\n","[18:17:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:17:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=  13.1s\n","[18:17:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:17:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.4s\n","[18:17:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:17:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.3s\n","[18:18:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:18:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.856 total time=   8.3s\n","[18:18:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:18:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.859 total time=   8.1s\n","[18:18:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:18:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.859 total time=   4.3s\n","[18:18:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:18:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.862 total time=   6.6s\n","[18:18:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:18:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.861 total time=   6.7s\n","[18:18:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:18:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.858 total time=   6.8s\n","[18:18:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:18:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.861 total time=  12.6s\n","[18:18:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:18:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.01, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=  13.3s\n","[18:19:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.870 total time=   5.2s\n","[18:19:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.871 total time=   5.6s\n","[18:19:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.868 total time=   5.1s\n","[18:19:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.870 total time=   5.0s\n","[18:19:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.871 total time=   5.0s\n","[18:19:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.873 total time=   8.0s\n","[18:19:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.874 total time=   3.9s\n","[18:19:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.871 total time=   3.9s\n","[18:19:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.873 total time=   4.1s\n","[18:19:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:19:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.872 total time=   4.1s\n","[18:20:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.870 total time=   2.7s\n","[18:20:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.871 total time=   3.1s\n","[18:20:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.868 total time=   2.7s\n","[18:20:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.870 total time=   6.4s\n","[18:20:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.871 total time=   5.6s\n","[18:20:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.873 total time=   8.2s\n","[18:20:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.874 total time=   7.9s\n","[18:20:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.871 total time=   8.6s\n","[18:20:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:20:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.873 total time=  14.7s\n","[18:21:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.872 total time=   7.5s\n","[18:21:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.870 total time=   2.5s\n","[18:21:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.871 total time=   2.5s\n","[18:21:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.868 total time=   2.7s\n","[18:21:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.870 total time=   2.7s\n","[18:21:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.871 total time=   3.0s\n","[18:21:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.873 total time=   6.3s\n","[18:21:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.874 total time=   4.1s\n","[18:21:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.871 total time=   6.9s\n","[18:21:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.873 total time=   8.5s\n","[18:21:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.872 total time=   8.0s\n","[18:21:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:21:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.870 total time=   5.1s\n","[18:22:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:22:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.871 total time=   5.4s\n","[18:22:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.868 total time=   5.1s\n","[18:22:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.870 total time=   5.1s\n","[18:22:16] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.871 total time=   5.1s\n","[18:22:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.873 total time=   7.7s\n","[18:22:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.874 total time=   4.6s\n","[18:22:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.871 total time=   3.8s\n","[18:22:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.873 total time=   4.1s\n","[18:22:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.872 total time=   4.1s\n","[18:22:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.870 total time=   2.7s\n","[18:22:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.871 total time=   2.7s\n","[18:22:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.868 total time=   2.7s\n","[18:22:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:22:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.870 total time=   6.6s\n","[18:23:00] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.871 total time=   5.4s\n","[18:23:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.873 total time=   8.1s\n","[18:23:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.874 total time=   8.5s\n","[18:23:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.871 total time=   8.0s\n","[18:23:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.873 total time=   7.7s\n","[18:23:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.872 total time=  10.7s\n","[18:23:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.870 total time=   2.7s\n","[18:23:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.871 total time=   2.5s\n","[18:23:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.868 total time=   2.5s\n","[18:23:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.870 total time=   2.6s\n","[18:23:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:23:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.871 total time=   2.7s\n","[18:24:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.873 total time=   4.3s\n","[18:24:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.874 total time=   4.1s\n","[18:24:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.871 total time=   4.1s\n","[18:24:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.873 total time=   8.1s\n","[18:24:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.872 total time=   8.1s\n","[18:24:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.870 total time=   5.1s\n","[18:24:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.871 total time=   5.1s\n","[18:24:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.868 total time=   5.0s\n","[18:24:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:24:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.870 total time=   5.1s\n","[18:24:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.871 total time=   5.1s\n","[18:24:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:24:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.873 total time=   7.6s\n","[18:25:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.874 total time=   8.2s\n","[18:25:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.871 total time=   5.3s\n","[18:25:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.873 total time=   4.2s\n","[18:25:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.872 total time=   4.1s\n","[18:25:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.870 total time=   2.9s\n","[18:25:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.871 total time=   2.7s\n","[18:25:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.868 total time=   2.7s\n","[18:25:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.870 total time=   2.7s\n","[18:25:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.871 total time=   2.7s\n","[18:25:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.873 total time=   7.7s\n","[18:25:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.874 total time=   8.1s\n","[18:25:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:25:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.871 total time=   7.9s\n","[18:26:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.873 total time=   8.6s\n","[18:26:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.872 total time=   8.2s\n","[18:26:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.873 total time=   8.0s\n","[18:26:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.873 total time=   7.8s\n","[18:26:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.872 total time=   4.0s\n","[18:26:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.871 total time=   3.9s\n","[18:26:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.872 total time=   4.1s\n","[18:26:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.874 total time=   6.3s\n","[18:26:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.875 total time=   6.2s\n","[18:26:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:26:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.873 total time=  11.3s\n","[18:27:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:27:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.872 total time=  13.0s\n","[18:27:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:27:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.874 total time=  12.3s\n","[18:27:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:27:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.873 total time=   8.0s\n","[18:27:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:27:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.873 total time=   7.8s\n","[18:27:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:27:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.872 total time=   6.0s\n","[18:27:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:27:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.871 total time=   3.8s\n","[18:28:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:28:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.872 total time=   4.2s\n","[18:28:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.874 total time=   6.3s\n","[18:28:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:28:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.875 total time=   6.2s\n","[18:28:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:28:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.873 total time=   9.5s\n","[18:28:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:28:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.872 total time=  12.5s\n","[18:28:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.874 total time=  11.9s\n","[18:28:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:28:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.873 total time=   8.7s\n","[18:29:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:29:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.873 total time=   8.1s\n","[18:29:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:29:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.872 total time=   7.8s\n","[18:29:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:29:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.871 total time=   6.0s\n","[18:29:23] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:29:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.872 total time=   3.9s\n","[18:29:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:29:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.874 total time=   6.8s\n","[18:29:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:29:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.875 total time=   8.7s\n","[18:29:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:29:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.873 total time=  34.5s\n","[18:30:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:30:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.872 total time=  33.1s\n","[18:30:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:30:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.874 total time=  13.6s\n","[18:31:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:31:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.873 total time=  14.2s\n","[18:31:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:31:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.873 total time=  13.7s\n","[18:31:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:31:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.872 total time=  14.2s\n","[18:31:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:31:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.871 total time=  12.1s\n","[18:31:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:31:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.872 total time=  18.9s\n","[18:32:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:32:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.874 total time=  11.4s\n","[18:32:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:32:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.875 total time=  13.0s\n","[18:32:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:32:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.873 total time=  42.9s\n","[18:33:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:33:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.872 total time=  23.3s\n","[18:33:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:33:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.874 total time=  10.3s\n","[18:33:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:33:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.873 total time=   8.1s\n","[18:34:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:34:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.873 total time=   6.9s\n","[18:34:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:34:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.872 total time=  13.1s\n","[18:34:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:34:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.871 total time=  17.1s\n","[18:34:43] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:34:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.872 total time=  15.5s\n","[18:34:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:34:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.874 total time=  19.1s\n","[18:35:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:35:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.875 total time=   7.4s\n","[18:35:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:35:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.873 total time=   7.6s\n","[18:35:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:35:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.872 total time=  13.0s\n","[18:35:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:35:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.874 total time=  28.7s\n","[18:36:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:36:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.873 total time=  17.4s\n","[18:36:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:36:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.873 total time=  13.3s\n","[18:36:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:36:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.872 total time=   5.4s\n","[18:36:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:36:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.871 total time=   6.7s\n","[18:36:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:36:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.872 total time=   7.3s\n","[18:37:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:37:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.874 total time=  23.5s\n","[18:37:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:37:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.875 total time=  26.7s\n","[18:37:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:37:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.873 total time=  20.3s\n","[18:38:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:38:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.872 total time=  11.3s\n","[18:38:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:38:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.874 total time=  11.4s\n","[18:38:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:38:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.873 total time=  20.4s\n","[18:38:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:38:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.873 total time=  20.6s\n","[18:39:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:39:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.872 total time=  16.3s\n","[18:39:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:39:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.871 total time=   7.5s\n","[18:39:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:39:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.872 total time=   3.8s\n","[18:39:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:39:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.874 total time=   6.1s\n","[18:39:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:39:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.875 total time=   6.2s\n","[18:39:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:39:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.873 total time=   6.3s\n","[18:40:05] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:40:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.872 total time=   9.8s\n","[18:40:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:40:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.874 total time=  12.7s\n","[18:40:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:40:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.873 total time=   7.9s\n","[18:40:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:40:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.873 total time=   9.7s\n","[18:40:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:40:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.872 total time=   8.1s\n","[18:40:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:40:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.871 total time=   7.6s\n","[18:41:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.872 total time=   7.7s\n","[18:41:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.874 total time=   5.9s\n","[18:41:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.875 total time=   6.1s\n","[18:41:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.873 total time=   6.2s\n","[18:41:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.872 total time=   6.2s\n","[18:41:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.1, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.874 total time=  11.5s\n","[18:41:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.863 total time=   5.0s\n","[18:41:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.865 total time=   5.0s\n","[18:41:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.863 total time=   4.9s\n","[18:41:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:41:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.863 total time=   4.8s\n","[18:42:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.862 total time=   5.7s\n","[18:42:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.862 total time=   7.4s\n","[18:42:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.862 total time=   7.7s\n","[18:42:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.862 total time=   7.4s\n","[18:42:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.861 total time=   4.1s\n","[18:42:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=   3.7s\n","[18:42:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.863 total time=   2.5s\n","[18:42:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.865 total time=   2.5s\n","[18:42:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.863 total time=   2.5s\n","[18:42:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.863 total time=   2.6s\n","[18:42:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.862 total time=   2.6s\n","[18:42:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.862 total time=   4.0s\n","[18:42:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:42:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.862 total time=   7.2s\n","[18:43:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.862 total time=   7.9s\n","[18:43:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.861 total time=   7.8s\n","[18:43:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=   7.8s\n","[18:43:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.863 total time=   4.8s\n","[18:43:32] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:43:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.865 total time=   4.8s\n","[18:43:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.863 total time=   4.8s\n","[18:43:42] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.863 total time=   4.7s\n","[18:43:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.862 total time=   4.7s\n","[18:43:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.862 total time=   7.3s\n","[18:43:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:43:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.862 total time=   3.8s\n","[18:44:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.862 total time=   4.0s\n","[18:44:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.861 total time=   4.3s\n","[18:44:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=   4.0s\n","[18:44:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.863 total time=   2.6s\n","[18:44:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.865 total time=   2.6s\n","[18:44:20] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.863 total time=   2.6s\n","[18:44:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.863 total time=   2.6s\n","[18:44:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.862 total time=   4.9s\n","[18:44:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.862 total time=   7.9s\n","[18:44:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.862 total time=   8.1s\n","[18:44:46] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.862 total time=   7.8s\n","[18:44:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:44:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.861 total time=   7.7s\n","[18:45:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=   7.7s\n","[18:45:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.863 total time=   4.9s\n","[18:45:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.865 total time=   4.8s\n","[18:45:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:45:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.863 total time=   4.8s\n","[18:45:24] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.863 total time=   3.6s\n","[18:45:27] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.862 total time=   2.4s\n","[18:45:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.862 total time=   3.8s\n","[18:45:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.862 total time=   3.9s\n","[18:45:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.862 total time=   4.0s\n","[18:45:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.861 total time=   4.0s\n","[18:45:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=   4.0s\n","[18:45:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.863 total time=   4.6s\n","[18:45:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.865 total time=   5.0s\n","[18:45:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:45:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.863 total time=   4.9s\n","[18:46:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.863 total time=   5.4s\n","[18:46:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.862 total time=   5.1s\n","[18:46:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.862 total time=   7.6s\n","[18:46:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.862 total time=   7.6s\n","[18:46:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.862 total time=   7.5s\n","[18:46:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.861 total time=   7.4s\n","[18:46:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=   7.5s\n","[18:46:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.863 total time=   2.4s\n","[18:46:54] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.865 total time=   2.4s\n","[18:46:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.863 total time=   2.4s\n","[18:46:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:46:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.863 total time=   2.5s\n","[18:47:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:47:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.862 total time=   2.5s\n","[18:47:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:47:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.862 total time=   5.4s\n","[18:47:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:47:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.862 total time=   4.0s\n","[18:47:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:47:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.862 total time=   7.9s\n","[18:47:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:47:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.861 total time=  17.7s\n","[18:47:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:47:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=  10.6s\n","[18:47:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:47:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.863 total time=   4.9s\n","[18:47:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:47:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.865 total time=   4.7s\n","[18:47:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.863 total time=   4.7s\n","[18:48:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.863 total time=   5.0s\n","[18:48:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:48:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.862 total time=   4.7s\n","[18:48:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.862 total time=   7.7s\n","[18:48:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.862 total time=   3.7s\n","[18:48:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.862 total time=   3.7s\n","[18:48:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.861 total time=   3.9s\n","[18:48:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=7, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=   4.0s\n","[18:48:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   3.8s\n","[18:48:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.859 total time=   3.9s\n","[18:48:45] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   5.3s\n","[18:48:50] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.0s\n","[18:48:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:48:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.854 total time=   7.6s\n","[18:49:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:49:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.858 total time=  11.6s\n","[18:49:17] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:49:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.859 total time=  11.7s\n","[18:49:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:49:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=  11.5s\n","[18:49:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:49:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=  11.4s\n","[18:49:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:49:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   6.7s\n","[18:49:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:49:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   3.7s\n","[18:50:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:50:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.859 total time=   4.0s\n","[18:50:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:50:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   4.6s\n","[18:50:11] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:50:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   4.4s\n","[18:50:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:50:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.854 total time=   7.0s\n","[18:50:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:50:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.858 total time=  18.4s\n","[18:50:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:50:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.859 total time=  20.2s\n","[18:51:01] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:51:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=  20.8s\n","[18:51:22] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:51:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=   6.1s\n","[18:51:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:51:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   6.5s\n","[18:51:34] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:51:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   6.4s\n","[18:51:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:51:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.859 total time=  17.7s\n","[18:51:58] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:51:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=  23.1s\n","[18:52:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:52:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   8.2s\n","[18:52:30] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:52:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.854 total time=   7.3s\n","[18:52:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:52:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.858 total time=  11.9s\n","[18:52:49] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:52:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.859 total time=   6.4s\n","[18:52:55] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:52:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=   6.9s\n","[18:53:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:53:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=   7.3s\n","[18:53:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:53:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=  15.3s\n","[18:53:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:53:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=  12.5s\n","[18:53:37] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:53:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.859 total time=  11.0s\n","[18:53:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:53:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.8s\n","[18:53:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:53:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=  11.0s\n","[18:54:08] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:54:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.854 total time=   5.6s\n","[18:54:13] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:54:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.858 total time=   5.6s\n","[18:54:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:54:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.859 total time=   6.0s\n","[18:54:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:54:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=   6.1s\n","[18:54:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:54:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=   8.0s\n","[18:54:39] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:54:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=7, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=  12.0s\n","[18:54:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:54:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   7.6s\n","[18:54:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:54:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.859 total time=   7.3s\n","[18:55:06] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:55:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   7.3s\n","[18:55:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:55:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.858 total time=   7.3s\n","[18:55:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:55:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=50;, score=0.854 total time=   7.2s\n","[18:55:28] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:55:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.858 total time=   7.1s\n","[18:55:35] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:55:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.859 total time=   5.9s\n","[18:55:41] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:55:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=   6.1s\n","[18:55:47] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:55:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.860 total time=   6.0s\n","[18:55:53] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:55:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=200, n_estimators=80;, score=0.854 total time=   8.6s\n","[18:56:02] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:56:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   8.7s\n","[18:56:10] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:56:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.859 total time=   7.7s\n","[18:56:18] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:56:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   7.4s\n","[18:56:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:56:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.858 total time=   7.4s\n","[18:56:33] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:56:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=50;, score=0.854 total time=   7.3s\n","[18:56:40] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:56:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.858 total time=  11.1s\n","[18:56:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:56:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.859 total time=   5.7s\n","[18:56:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:56:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=   6.0s\n","[18:57:03] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:57:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.860 total time=   6.1s\n","[18:57:09] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:57:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=30, min_samples_split=250, n_estimators=80;, score=0.854 total time=   6.1s\n","[18:57:15] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:57:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   5.6s\n","[18:57:21] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:57:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.859 total time=   8.5s\n","[18:57:29] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:57:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=  18.8s\n","[18:57:48] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:57:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.858 total time=   7.8s\n","[18:57:56] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:57:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=50;, score=0.854 total time=   7.9s\n","[18:58:04] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.858 total time=   9.8s\n","[18:58:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.859 total time=   5.6s\n","[18:58:19] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=   6.0s\n","[18:58:25] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.860 total time=   6.1s\n","[18:58:31] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"name":"stdout","output_type":"stream","text":["[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=200, n_estimators=80;, score=0.854 total time=   6.1s\n","[18:58:38] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   6.3s\n","[18:58:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.859 total time=   7.7s\n","[18:58:52] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   7.5s\n","[18:58:59] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:58:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.858 total time=   7.7s\n","[18:59:07] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:59:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=50;, score=0.854 total time=   7.3s\n","[18:59:14] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:59:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 1/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.858 total time=  11.6s\n","[18:59:26] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:59:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 2/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.859 total time=  10.5s\n","[18:59:36] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:59:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 3/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=   7.9s\n","[18:59:44] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:59:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 4/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.860 total time=   7.3s\n","[18:59:51] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[18:59:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV 5/5] END learning_rate=0.5, max_depth=10, max_features=15, min_samples_leaf=50, min_samples_split=250, n_estimators=80;, score=0.854 total time=   6.0s\n","[18:59:57] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["[18:59:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["GridSearchCV(cv=5,\n","             estimator=XGBClassifier(base_score=None, booster=None,\n","                                     colsample_bylevel=None,\n","                                     colsample_bynode=None,\n","                                     colsample_bytree=None,\n","                                     enable_categorical=False, gamma=None,\n","                                     gpu_id=None, importance_type=None,\n","                                     interaction_constraints=None,\n","                                     learning_rate=None, max_delta_step=None,\n","                                     max_depth=None, min_child_weight=None,\n","                                     missing=nan, monotone_constraints=None,...\n","                                     num_parallel_tree=None, predictor=None,\n","                                     random_state=None, reg_alpha=None,\n","                                     reg_lambda=None, scale_pos_weight=None,\n","                                     subsample=None, tree_method=None,\n","                                     validate_parameters=None, verbosity=None),\n","             param_grid={'learning_rate': [0.01, 0.1, 0.5],\n","                         'max_depth': [7, 10], 'max_features': [7, 15],\n","                         'min_samples_leaf': [30, 50],\n","                         'min_samples_split': [200, 250],\n","                         'n_estimators': [50, 80]},\n","             scoring='roc_auc', verbose=4)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["xgbsearch = GridSearchCV(estimator=modelo, param_grid=XGB_hyperparameters, cv=5, verbose=4, scoring='roc_auc')\n","xgbsearch.fit(hamburguesas_train_values_bin, hamburguesas_train_target_enc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1638931018020,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"BM4D8AADdMij","outputId":"264cd5f0-5ae7-4eac-8020-24ff45aaff77"},"outputs":[{"data":{"text/plain":["{'learning_rate': 0.1,\n"," 'max_depth': 10,\n"," 'max_features': 7,\n"," 'min_samples_leaf': 30,\n"," 'min_samples_split': 200,\n"," 'n_estimators': 80}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["parametros = xgbsearch.best_params_\n","parametros"]},{"cell_type":"markdown","metadata":{"id":"vWZiucua57BK"},"source":[" * learning_rate = 0.1\n"," * max_depth = 10\n"," * max_features = 7\n"," * min_samples_leaf = 30\n"," * min_samples_split = 200\n"," * n_estimators = 80"]},{"cell_type":"markdown","metadata":{"id":"IKovV0aYBcMe"},"source":["Como ya encontramos los mejores hiperparámetros, creamos un diccionario con dichos valores (esto es para cuando no podamos hacer el `.best_params_` porque no ejecutamos GridSearch cuando usamos el notebook otro día debido al tiempo que insume)"]},{"cell_type":"markdown","metadata":{"id":"bgo7cfW-5-CS"},"source":["## Entrenamos y vemos cómo nos va"]},{"cell_type":"markdown","metadata":{"id":"E1g6HpTkRM6W"},"source":["Hay un bug, por eso falta el feature `barrio_4`en `hamburguesas_val_dev_values_bin`, por lo que agreagamos ese feature en dicho dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8V2VCrQ6Mmj"},"outputs":[],"source":["hamburguesas_val_dev_values_bin['barrio_4'] = hamburguesas_train_values_bin['barrio_4']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7Q8uFi4NaCt"},"outputs":[],"source":["parametros = {'learning_rate': 0.1,\n","              'max_depth': 10,\n","              'max_features': 7,\n","              'min_samples_leaf': 30,\n","              'min_samples_split': 200,\n","              'n_estimators': 80}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5988,"status":"ok","timestamp":1639018021253,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"RkwfdzWq5q45","outputId":"75ac363c-c2be-4194-f9f7-65ac9c658bc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[19:45:12] WARNING: ../src/learner.cc:576: \n","Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } might not be used.\n","\n","  This could be a false alarm, with some parameters getting used by language bindings but\n","  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n","  but getting flagged wrongly here. Please open an issue if you find any such cases.\n","\n","\n","[19:45:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]},{"data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n","              gamma=0, gpu_id=-1, importance_type=None,\n","              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n","              max_depth=10, max_features=7, min_child_weight=1,\n","              min_samples_leaf=30, min_samples_split=200, missing=nan,\n","              monotone_constraints='()', n_estimators=80, n_jobs=8,\n","              num_parallel_tree=1, predictor='auto', random_state=0,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n","              tree_method='exact', validate_parameters=1, ...)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["modelo = XGBClassifier(**parametros)\n","modelo.fit(hamburguesas_train_values_bin, hamburguesas_train_target_enc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2zAyHvSYE0_"},"outputs":[],"source":["prediccion = modelo.predict_proba(hamburguesas_val_dev_values_bin)[:,1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1639018075087,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"73IYRImf6LGK","outputId":"3ddd68e4-3760-419f-dbd5-4b440a66b49d"},"outputs":[{"data":{"text/plain":["0.8715561298691621"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["roc_auc_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVhUKakO6Mmp"},"outputs":[],"source":["prediccion = modelo.predict(hamburguesas_val_dev_values_bin)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":277,"status":"ok","timestamp":1639018078278,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"Rip_jvraR5kv","outputId":"bed3c687-ea4a-4248-9b7b-33e479402e16"},"outputs":[{"data":{"text/plain":["0.8508103979185067"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["accuracy_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1639018079807,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"hrQVccmZR8wG","outputId":"aa5eb78a-41d0-484e-c594-448539a66846"},"outputs":[{"data":{"text/plain":["0.5002728959720555"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["recall_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1639018081842,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"JAS1_MgkR9bO","outputId":"43aa60f4-4659-40b0-bfcd-c09cc077be16"},"outputs":[{"data":{"text/plain":["0.7326938449240608"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["precision_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1639018083326,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"pu6H7lRaEneH","outputId":"899a9028-ab12-4001-e325-71a1eaa765b0"},"outputs":[{"data":{"text/plain":["0.5945770627919045"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["f1_score(hamburguesas_val_dev_target_enc, prediccion)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":290,"status":"ok","timestamp":1639018085467,"user":{"displayName":"Carlos Martín Stefanelli D'Elias","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggi2AWY9ASWIaOOWdfMZgc2O7JvCXEYEiqt1Jtk=s64","userId":"13955354760774059985"},"user_tz":180},"id":"MmNzBjUrR9_P","outputId":"bb44af2d-4def-4826-d90b-110b35f08bc1"},"outputs":[{"data":{"text/plain":["{'tn': 31060, 'fp': 1672, 'fn': 4578, 'tp': 4583}"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["cm = confusion_matrix(hamburguesas_val_dev_target_enc, prediccion)\n","{'tn': cm[0, 0], 'fp': cm[0, 1],\n","'fn': cm[1, 0], 'tp': cm[1, 1]}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7L0Kvj0l6Mmw","outputId":"dbd64808-9a70-40f7-99de-737da91a9665"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 448x336 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=modelo.classes_)\n","disp.plot()\n","plt.show()"]},{"cell_type":"markdown","source":["En este caso, la tendencia del modelo es que tiende a predecir 0 sobre 1 porque si vemos la otra diagonal (la de \"pifiadas\") vemos que hay más casos de era 1 y lo predijo como 0, respecto de era 0 y lo predijo como 1. Por otro lado, la diagonal principal, es \"saludable\", pues hay una diferencia muy alta entre los casos en los que era 0 y predijo 0 respecto de los de la otra diagonal y lo mismo ocurrió en los casos en los que era 1 y predijo 1 pero con una diferencia no tan notoria. "],"metadata":{"id":"A3YficyV6g7p"}},{"cell_type":"markdown","source":["El modelo predijo bien más positivos (35638 casos, 85,07%) que negativos (6255 casos, 14,93%) porque hay una gran cantidad de verdaderos positivos y (en menor medida) falsos positivos, mientras que los verdaderos negativos y falsos negativos hay menos."],"metadata":{"id":"KRiwHV1owMK5"}},{"cell_type":"markdown","metadata":{"id":"28ye4WvJpErJ"},"source":["## Predicciones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYcbZBMXpGLB"},"outputs":[],"source":["hamburguesas_test_ohe = preprocessing_mean_imputer_standar_escaler_one_hot_encoding_binary_encoding(\n","    None,\n","    None,\n","    None,\n","    hamburguesas_test,\n","    True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SokZB1aGF3vl"},"outputs":[],"source":["predicciones = modelo.predict(hamburguesas_test_ohe)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pENHki52F6_-"},"outputs":[],"source":["auxiliar = hamburguesas_test.join(hamburguesas_target).reset_index()\n","auxiliar = auxiliar[['id', 'llovieron_hamburguesas_al_dia_siguiente']]\n","auxiliar = auxiliar.set_index('id')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Ut3vxX-F9gl"},"outputs":[],"source":["nuestra_prediccion = pd.DataFrame(data=predicciones, columns=auxiliar.columns, index=auxiliar.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQrevEo-F_42"},"outputs":[],"source":["for v in nuestra_prediccion.columns:\n","  nuestra_prediccion.loc[:, v] = nuestra_prediccion[v].map({0: 'no', 1: 'si',})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJz7Y8aJ6Mm2"},"outputs":[],"source":["nuestra_prediccion.to_csv('XGBoost_mean_imputer_standar_escaler_one_hot_encoding_binary_encoding.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuInxVwoGCQd"},"outputs":[],"source":["nuestra_prediccion.to_csv('/drive/My Drive/TP_Datos_2C2021/parte_2/XGBoost.csv')"]}],"metadata":{"colab":{"collapsed_sections":["FsFIZcb60AGa"],"name":"XGBoost.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}